"""
Visualisation et analyse des rÃ©sultats d'amÃ©lioration du XGBoost
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent.parent.parent.parent.resolve()))
import models.configs.global_config as cfg
from models.configs.save_paths import SavePaths

# Configuration style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)


def plot_feature_comparison(results_file: Path, with_xg: bool = False):
    """
    Compare les performances selon le nombre de features
    
    Args:
        results_file: Chemin du fichier de rÃ©sultats
        with_xg: Si True, sauvegarde dans le dossier xg
    """
    df = pd.read_csv(results_file)
    test_df = df[df['dataset'] == 'test'].copy()
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    metrics = ['log_loss', 'accuracy', 'roi']
    titles = ['Log Loss (â†“ meilleur)', 'Accuracy (â†‘ meilleur)', 'ROI % (â†‘ meilleur)']
    
    for ax, metric, title in zip(axes, metrics, titles):
        # Trier par mÃ©trique
        if metric in ['accuracy', 'roi']:
            sorted_df = test_df.sort_values(metric, ascending=False)
        else:
            sorted_df = test_df.sort_values(metric, ascending=True)
        
        # Plot
        bars = ax.barh(sorted_df['model'], sorted_df[metric])
        
        # Colorer le meilleur
        bars[0].set_color('green')
        bars[0].set_alpha(0.7)
        
        ax.set_xlabel(title)
        ax.set_title(f"{title}")
        ax.grid(axis='x', alpha=0.3)
        
        # Annoter les valeurs
        for i, (idx, row) in enumerate(sorted_df.iterrows()):
            value = row[metric]
            if pd.notna(value):
                ax.text(value, i, f" {value:.3f}", 
                       va='center', fontsize=9)
    
    plt.tight_layout()
    
    # Sauvegarder
    plot_path = SavePaths.get_result_path(
        category='step2b_optimization',
        filename='feature_comparison_plot.png',
        with_xg=with_xg
    )
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    print(f"âœ… Graphique sauvegardÃ© : {plot_path}")
    plt.close()


def plot_metrics_evolution(results_file: Path, with_xg: bool = False):
    """
    Montre l'Ã©volution des mÃ©triques sur TRAIN/CV/TEST
    
    Args:
        results_file: Chemin du fichier de rÃ©sultats
        with_xg: Si True, sauvegarde dans le dossier xg
    """
    df = pd.read_csv(results_file)
    
    models = df['model'].unique()
    datasets = ['train', 'cv', 'test']
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    metrics = ['log_loss', 'accuracy', 'brier_score']
    titles = ['Log Loss', 'Accuracy', 'Brier Score']
    
    for ax, metric, title in zip(axes, metrics, titles):
        for model in models:
            model_data = df[df['model'] == model]
            values = [model_data[model_data['dataset'] == d][metric].values[0] 
                     for d in datasets]
            ax.plot(datasets, values, marker='o', label=model, linewidth=2)
        
        ax.set_title(title)
        ax.set_ylabel(title)
        ax.legend(loc='best', fontsize=8)
        ax.grid(alpha=0.3)
    
    plt.suptitle("Ã‰volution des mÃ©triques (Train â†’ CV â†’ Test)", 
                fontsize=14, y=1.02)
    plt.tight_layout()
    
    # Sauvegarder
    plot_path = SavePaths.get_result_path(
        category='step2b_optimization',
        filename='metrics_evolution_plot.png',
        with_xg=with_xg
    )
    plt.savefig(plot_path, dpi=150, bbox_inches='tight')
    print(f"âœ… Graphique sauvegardÃ© : {plot_path}")
    plt.close()


def generate_summary_report(results_dir: Path, with_xg: bool = False):
    """GÃ©nÃ¨re un rapport complet des rÃ©sultats"""
    
    print(f"\n{'='*70}")
    print(f"  RAPPORT RÃ‰CAPITULATIF - {'AVEC' if with_xg else 'SANS'} XG")
    print(f"{'='*70}\n")
    
    # Charger les rÃ©sultats de feature comparison
    feature_comp_file = SavePaths.get_result_path(
        category='step2b_optimization',
        filename='feature_comparison.csv',
        with_xg=with_xg
    )

    if not feature_comp_file.exists():
        print(f"âŒ Fichier introuvable : {feature_comp_file}")
        print(f"   ExÃ©cute d'abord 'step2b_optimization.py'")
        return
    
    df = pd.read_csv(feature_comp_file)
    
    # RÃ©sultats sur le TEST set
    test_df = df[df['dataset'] == 'test'].sort_values('log_loss')
    
    print("ğŸ“Š CLASSEMENT DES MODÃˆLES (sur TEST set)")
    print("-" * 70)
    print(test_df[['model', 'accuracy', 'log_loss', 
                   'brier_score', 'roi']].to_string(index=False))
    
    # Meilleur modÃ¨le
    best_model = test_df.iloc[0]
    print(f"\nğŸ† MEILLEUR MODÃˆLE : {best_model['model']}")
    print(f"   â€¢ Accuracy           : {best_model['accuracy']:.4f}")
    print(f"   â€¢ Log Loss           : {best_model['log_loss']:.4f}")
    print(f"   â€¢ Brier Score        : {best_model['brier_score']:.4f}")
    if pd.notna(best_model['roi']):
        print(f"   â€¢ ROI                : {best_model['roi']:.2f}%")
        print(f"   â€¢ Profit             : ${best_model['profit']:.2f}")
        print(f"   â€¢ Nombre de paris    : {best_model['n_bets']:.0f}")
    
    # Comparaison avec baseline
    baseline_file = SavePaths.get_result_path(
        category='step2a_baseline',
        filename=f'baseline_comparison_{"xg" if with_xg else "no_xg"}.csv',
        with_xg=with_xg
    )
    
    if baseline_file.exists():
        baseline_df = pd.read_csv(baseline_file)
        baseline_test = baseline_df[baseline_df['dataset'] == 'test']
        
        print(f"\nğŸ“ˆ AMÃ‰LIORATION vs BASELINE XGBOOST")
        print("-" * 70)
        
        if 'XGBoost' in baseline_test['model'].values:
            baseline_xgb = baseline_test[baseline_test['model'] == 'XGBoost'].iloc[0]
            
            acc_improv = (best_model['accuracy'] - baseline_xgb['accuracy']) * 100
            log_improv = (baseline_xgb['log_loss'] - best_model['log_loss']) / baseline_xgb['log_loss'] * 100
            brier_improv = (baseline_xgb['brier_score'] - best_model['brier_score']) / baseline_xgb['brier_score'] * 100
            
            print(f"   â€¢ Accuracy    : {acc_improv:+.2f} points")
            print(f"   â€¢ Log Loss    : {log_improv:+.2f}% (amÃ©lioration)")
            print(f"   â€¢ Brier Score : {brier_improv:+.2f}% (amÃ©lioration)")
            
            if pd.notna(best_model['roi']) and pd.notna(baseline_xgb['roi']):
                roi_improv = best_model['roi'] - baseline_xgb['roi']
                print(f"   â€¢ ROI         : {roi_improv:+.2f} points")
    
    # VÃ©rifier si le modÃ¨le final existe
    final_results_file = SavePaths.get_result_path(
        category='step2b_optimization',
        filename='final_results.csv',
        with_xg=with_xg
    )
    if final_results_file.exists():
        print(f"\nâœ… RÃ©sultats du modÃ¨le optimisÃ© disponibles dans :")
        print(f"   {final_results_file}")
        
        final_df = pd.read_csv(final_results_file)
        final_test = final_df[final_df['dataset'] == 'test'].iloc[0]
        
        print(f"\nğŸ¯ MODÃˆLE FINAL OPTIMISÃ‰ (avec hyperparameter tuning)")
        print("-" * 70)
        print(f"   â€¢ Accuracy           : {final_test['accuracy']:.4f}")
        print(f"   â€¢ Log Loss           : {final_test['log_loss']:.4f}")
        print(f"   â€¢ Brier Score        : {final_test['brier_score']:.4f}")
        if pd.notna(final_test['roi']):
            print(f"   â€¢ ROI                : {final_test['roi']:.2f}%")
    
    print(f"\n{'='*70}\n")


def main():
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        VISUALISATION ET ANALYSE DES RÃ‰SULTATS                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Choix : avec ou sans XG
    with_xg = False  # ğŸ”¹ Change selon tes besoins
    
    results_dir = cfg.RESULTS_WITH_XG_DIR if with_xg else cfg.RESULTS_NO_XG_DIR
    
    # 1. GÃ©nÃ©rer le rapport
    generate_summary_report(results_dir, with_xg=with_xg)
    
    # 2. CrÃ©er les visualisations
    feature_comp_file = SavePaths.get_result_path(
        category='step2b_optimization',
        filename='feature_comparison.csv',
        with_xg=with_xg
    )
    
    if feature_comp_file.exists():
        print("\nğŸ“Š GÃ©nÃ©ration des graphiques...")
        plot_feature_comparison(feature_comp_file, with_xg)
        plot_metrics_evolution(feature_comp_file, with_xg)
        print("\nâœ… Visualisations crÃ©Ã©es avec succÃ¨s !")
    else:
        print(f"\nâš ï¸ Fichier de rÃ©sultats introuvable : {feature_comp_file}")
        print("   ExÃ©cute d'abord 'xgboost_improved.py'")


if __name__ == "__main__":
    main()
